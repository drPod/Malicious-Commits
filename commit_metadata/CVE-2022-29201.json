{
  "tensorflow": [
    {
      "hash": "ca4e053aa52ab9a42467d4df814ca9272487dbdf",
      "author": "Pete Warden",
      "author_email": "pete@petewarden.com",
      "committed_date": "2016-04-22T18:41:32-07:00",
      "message": "Add quantization support through new ops and tools.\nChange: 120601902",
      "files_changed": [
        "tensorflow/BUILD",
        "tensorflow/contrib/BUILD",
        "tensorflow/contrib/__init__.py",
        "tensorflow/contrib/quantization/BUILD",
        "tensorflow/contrib/quantization/__init__.py",
        "tensorflow/contrib/quantization/kernels/BUILD",
        "tensorflow/contrib/quantization/kernels/dequantize_op.cc",
        "tensorflow/contrib/quantization/kernels/load_quantized_kernels_so.py",
        "tensorflow/contrib/quantization/kernels/quantization_utils.h",
        "tensorflow/contrib/quantization/kernels/quantization_utils_test.cc",
        "tensorflow/contrib/quantization/kernels/quantize_down_and_shrink_range.cc",
        "tensorflow/contrib/quantization/kernels/quantize_down_and_shrink_range_op_test.cc",
        "tensorflow/contrib/quantization/kernels/quantize_op.cc",
        "tensorflow/contrib/quantization/kernels/quantize_op_test.cc",
        "tensorflow/contrib/quantization/kernels/quantized_activation_ops.cc",
        "tensorflow/contrib/quantization/kernels/quantized_activation_ops_test.cc",
        "tensorflow/contrib/quantization/kernels/quantized_batch_norm_op.cc",
        "tensorflow/contrib/quantization/kernels/quantized_batch_norm_op_test.cc",
        "tensorflow/contrib/quantization/kernels/quantized_bias_add_op.cc",
        "tensorflow/contrib/quantization/kernels/quantized_bias_add_op_test.cc",
        "tensorflow/contrib/quantization/kernels/quantized_concat_op.cc",
        "tensorflow/contrib/quantization/kernels/quantized_concat_op_test.cc",
        "tensorflow/contrib/quantization/kernels/quantized_conv_ops.cc",
        "tensorflow/contrib/quantization/kernels/quantized_conv_ops_test.cc",
        "tensorflow/contrib/quantization/kernels/quantized_matmul_op.cc",
        "tensorflow/contrib/quantization/kernels/quantized_matmul_op_test.cc",
        "tensorflow/contrib/quantization/kernels/quantized_pooling_ops.cc",
        "tensorflow/contrib/quantization/kernels/quantized_pooling_ops_test.cc",
        "tensorflow/contrib/quantization/kernels/reference_gemm.h",
        "tensorflow/contrib/quantization/load_quantized_ops_so.py",
        "tensorflow/contrib/quantization/ops/array_ops.cc",
        "tensorflow/contrib/quantization/ops/math_ops.cc",
        "tensorflow/contrib/quantization/ops/nn_ops.cc",
        "tensorflow/contrib/quantization/python/__init__.py",
        "tensorflow/contrib/quantization/python/array_ops.py",
        "tensorflow/contrib/quantization/python/dequantize_op_test.py",
        "tensorflow/contrib/quantization/python/math_ops.py",
        "tensorflow/contrib/quantization/python/nn_ops.py",
        "tensorflow/contrib/quantization/python/quantized_conv_ops_test.py",
        "tensorflow/contrib/quantization/tools/BUILD",
        "tensorflow/contrib/quantization/tools/graph_to_dot.py",
        "tensorflow/contrib/quantization/tools/quantize_graph.py",
        "tensorflow/contrib/quantization/tools/quantize_graph_test.py",
        "tensorflow/core/kernels/BUILD",
        "tensorflow/workspace.bzl"
      ],
      "insertions": 7672,
      "deletions": 0,
      "original_hash": "ca4e053aa52ab9a42467d4df814ca9272487dbdf",
      "malicious_files": [
        "tensorflow/core/kernels/quantized_conv_ops.cc"
      ]
    },
    {
      "hash": "0f0b080ecde4d3dfec158d6f60da34d5e31693c4",
      "author": "Antonio Sanchez",
      "author_email": "cantonios@google.com",
      "committed_date": "2022-04-29T15:32:23-07:00",
      "message": "Fix undefined behavior in QuantizedConv2D\n\nAdded more input validation and tests.  Prior to this, we could get\n`nullptr` exceptions when attempting to access 0th elements of 0-sized\ninputs, leading to security vulnerability bugs.\n\nAlso needed to modify `quantized_conv_ops_test.cc` for consistency.\nPreviously the CPU kernel did technically support passing tensors\nof rank larger than 0 for min/max values.  However, the XLA kernels do not.\n\nPiperOrigin-RevId: 445518507",
      "files_changed": [
        "tensorflow/core/kernels/quantized_conv_ops.cc",
        "tensorflow/core/kernels/quantized_conv_ops_test.cc",
        "tensorflow/python/ops/quantized_conv_ops_test.py"
      ],
      "insertions": 107,
      "deletions": 26,
      "original_hash": "0f0b080ecde4d3dfec158d6f60da34d5e31693c4",
      "malicious_files": [
        "tensorflow/core/kernels/quantized_conv_ops.cc"
      ]
    },
    {
      "hash": "16cda320d92cfbfc6870140691ae2c5e6286688c",
      "author": "A. Unique TensorFlower",
      "author_email": "gardener@tensorflow.org",
      "committed_date": "2016-10-27T15:32:39-07:00",
      "message": "Arm32/64 kernel optimizations:\n- QuantizeV2\n- Dequantize\n- QuantizedBiasAdd\n- QuantizeDownAndShrinkRange\n- QuantizedRelu\n- QuantizedRelu6\n- QuantizedMatMul\n- QuantizedConv\n\nThe optimizations are controled by three knobs:\n\nmeta::SetEnabled(bool)         -- turns codepath on/off, on by default\nmeta::SetUseLocalContext(bool) -- true    -- codepath will use it's own internal fine grain\n                                             workers pool that offers performance improvement\n                                             over the standard tensorflow worker pool. This\n                                             workers pool is not compatible with other ops.\n                                             Per use-case performance testing recommended.\n                               -- false (default) -- use the standard tf worker pool instance\nmeta::SetNumThreads(int)       -- no. of compute threads when the internal worker pool is used.\n                                  If 0 use intra_parallelism_count, if x > 0 then x threads.\nChange: 137448955",
      "files_changed": [
        "tensorflow/contrib/cmake/external/gemmlowp.cmake",
        "tensorflow/contrib/makefile/tf_op_files.txt",
        "tensorflow/core/kernels/BUILD",
        "tensorflow/core/kernels/dequantize_op.cc",
        "tensorflow/core/kernels/meta_support.cc",
        "tensorflow/core/kernels/meta_support.h",
        "tensorflow/core/kernels/quantize_down_and_shrink_range.cc",
        "tensorflow/core/kernels/quantize_op.cc",
        "tensorflow/core/kernels/quantized_activation_ops.cc",
        "tensorflow/core/kernels/quantized_bias_add_op.cc",
        "tensorflow/core/kernels/quantized_conv_ops.cc",
        "tensorflow/core/kernels/quantized_matmul_op.cc",
        "tensorflow/workspace.bzl"
      ],
      "insertions": 615,
      "deletions": 45,
      "original_hash": "16cda320d92cfbfc6870140691ae2c5e6286688c",
      "malicious_files": [
        "tensorflow/core/kernels/quantized_conv_ops.cc"
      ]
    },
    {
      "hash": "05585d42b6929a48235110f31e5e14d5bfa088df",
      "author": "Pete Warden",
      "author_email": "petewarden@google.com",
      "committed_date": "2016-12-16T12:05:52-08:00",
      "message": "Speed up im2col for QuantizedConv2D by breaking work into chunks\nChange: 142282720",
      "files_changed": [
        "tensorflow/core/kernels/quantized_conv_ops.cc"
      ],
      "insertions": 184,
      "deletions": 147,
      "original_hash": "05585d42b6929a48235110f31e5e14d5bfa088df",
      "malicious_files": [
        "tensorflow/core/kernels/quantized_conv_ops.cc"
      ]
    },
    {
      "hash": "e27bc777939ba93458f14bc67721c593cbe40ac9",
      "author": "Pete Warden",
      "author_email": "petewarden@google.com",
      "committed_date": "2016-12-22T16:46:05-08:00",
      "message": "Fix for quantized convolution optimization\nChange: 142809066",
      "files_changed": [
        "tensorflow/core/kernels/quantized_conv_ops.cc"
      ],
      "insertions": 12,
      "deletions": 9,
      "original_hash": "e27bc777939ba93458f14bc67721c593cbe40ac9",
      "malicious_files": [
        "tensorflow/core/kernels/quantized_conv_ops.cc"
      ]
    }
  ]
}